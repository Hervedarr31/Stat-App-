{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bert_Predict.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrEAfGCL51WL"
      },
      "source": [
        "Les cellules de ce Notebook sont à copier dans Bert.ipynb, après avoir entrainé le modèle.  Il permet de sortir les tokens (décodés) qui sont prédits dans la classe positive (label = 1)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRCCF9gcZl9v"
      },
      "source": [
        "%run /content/drive/MyDrive/Colab_Notebooks/Predictions.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNJ8yvVr4eei"
      },
      "source": [
        "df_predict = pd.read_csv('/content/drive/MyDrive/Colab_Notebooks/2019-01-08-editos-radio.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9N4U81445zj"
      },
      "source": [
        "On crée une nouvelle base, qui ressemble à une base issue de Doccano **Attention :** l'user que l'on précise ne sert à rien mais il faudra garder le même pour la prédiction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVyjC1Gg4yrR"
      },
      "source": [
        "new = pd.DataFrame(columns=['id', 'text', 'annotations',])\n",
        "ligne1 = pd.DataFrame({'id': [0], 'text' : ['pas de texte'], 'annotations': [[{'end_offset': 3, 'label': 516, 'start_offset': 2, 'user': 55}]]})\n",
        "new = pd.concat([new,ligne1])\n",
        "new = new.set_index('id')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFEu8-86ZHtQ"
      },
      "source": [
        "Ensuite on met le texte qu'on veut traiter "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8vzyP9FZAi2"
      },
      "source": [
        "new['text'][0] = df_predict['texte'][120]\n",
        "new"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTa5JWuAUS_y"
      },
      "source": [
        "def finition(traduit):\n",
        "  liste =traduit[0].split()\n",
        "  liste_finale = []\n",
        "  for i in range(len(liste)-1):\n",
        "    if liste[i] == 'stop':\n",
        "      if liste[i+1] !='stop':\n",
        "        liste_finale += [liste[i]]\n",
        "    else:\n",
        "      liste_finale += [liste[i]]\n",
        "  return(liste_finale)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_RA1QQm4YCa"
      },
      "source": [
        "def predict_decode_2(df,user):\n",
        "  data_predict = get_predict_data(df,user=user) #on prépare les données pour la prédiction\n",
        "  data_decode = get_decode_data(df) #on prépare la base pour retrouver les token\n",
        "\n",
        "  prediction = trainer.predict(data_predict) #on fait la prédiction\n",
        "  predicted = np.argmax(prediction[0],axis=2) #on sort les labels\n",
        "\n",
        "  to_decode = decodeur_2(predicted,data_decode)#on récupère les tokens pour les labels 1\n",
        "\n",
        "  traduit = [tokenizer.decode(to_decode)] #on décode les token\n",
        "  resultat = finition(traduit)\n",
        "  sortie = [\" \".join(resultat)]\n",
        "  return(sortie)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbG30RS35Q4-"
      },
      "source": [
        "predict_decode_2(new,user=55)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwO2alr05SL3"
      },
      "source": [
        ""
      ]
    }
  ]
}