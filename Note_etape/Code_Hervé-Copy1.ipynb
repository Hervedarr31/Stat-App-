{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse descriptive de la base de données "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importation de la base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "from operator import add\n",
    "from tqdm import tqdm\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.fr import French\n",
    "from collections import Counter\n",
    "import re\n",
    "import fr_core_news_sm,fr_core_news_lg\n",
    "nlp = fr_core_news_lg.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"2019-01-08-editos-radio.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On enlève les \"\\n\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['auteur'] = df['auteur'].apply(lambda x: \" \".join(str(x).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['texte']= df['texte'].apply(lambda x: \" \".join((str(x).split())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistiques descriptives textuelles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Nombre de phrases "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(text, delimiters = [\".\",\"?\",\"!\",\"...\"], maxsplit=0):\n",
    "    #fonction servant juste à séparer les phrases dans un texte sous forme de liste\n",
    "    delimiters = '|'.join(map(re.escape, delimiters))\n",
    "    phrases = re.split(delimiters, text, maxsplit)\n",
    "    return(list(filter(lambda a: a != '', phrases)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def nombre_phrases(text):\n",
    "    return(len(split(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Nombre phrases'] = df['texte'].apply(nombre_phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Phrases interrogatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Interrogatives'] = df['texte'].apply(lambda x : x.count('?'))\n",
    "#df['Pourcentage interrogatives']=round((df['Interrogatives']/df['Nombre phrases'])*100,2)\n",
    "#print(\"Proportion de phrases interrogatives : \", df['Pourcentage interrogatives'].mean(), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Est-ce notable ? A comparer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Des différences stylistiques entre les éditorialistes ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pd.DataFrame(df.groupby('auteur').mean().reset_index()).plot.bar(x='auteur', y='Pourcentage interrogatives', figsize=(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Repères (lieux, personnes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counter_label(text,label):\n",
    "    doc=nlp(text)\n",
    "    c=0\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == label:\n",
    "            c+=1\n",
    "    return(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Lieux'] = df['texte'].apply(lambda x: counter_label(x,'LOC'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Personnes'] = df['texte'].apply(lambda x: counter_label(x,'PER'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Lieux par phrase'] = round((df['Lieux']/df['Nombre phrases']),2)\n",
    "#df['Personnes par phrase'] = round((df['Personnes']/df['Nombre phrases']),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Chiffres / Pourcentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Pourcentages'] = df['texte'].apply(lambda x : x.count('%'))\n",
    "#df['Pourcentages par phrase'] = round((df['Pourcentages']/df['Nombre phrases']),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Personnalités politiques "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin de distinguer les personnalités politiques citées dans un édito, on crée une liste composées des présidents et ministres de la\n",
    "Ve République à laquelle on a rajouté les députés et sénateurs en activité, puis les eurodéputés élus en 2019 ainsi que les candidats à la présidentielle de 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Scrap_perso_politiques_Fr.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "POLITICIANS = Ministres_Ve + Presidents + Deputes + Senateurs + eurodeputes + Candidats_2017\n",
    "POLITICIANS += ['JL Mélenchon', 'Marine le Pen', 'J.L. Mélenchon', 'JL. Mélenchon', 'Benoit Hamon']\n",
    "\n",
    "# On importe le PhraseMatcher et on l'initialise\n",
    "from spacy.matcher import PhraseMatcher\n",
    "matcher_politician = PhraseMatcher(nlp.vocab)\n",
    "\n",
    "# On crée des motifs objets et  on les ajoute au matcher\n",
    "\n",
    "patterns = list(nlp.pipe(POLITICIANS))\n",
    "matcher_politician.add(\"Politicians\", None, *patterns, on_match=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appelle le matcher sur le document de test et affiche le résultat\n",
    "\n",
    "essai =\" François Hollande devrait s'appuyer sur Michel Sapin et son expérience. François Hollande contre Gérard Larcher,Mélenchon\"\n",
    "doc_essai = nlp(essai)\n",
    "matches_essai = matcher_politician(doc_essai)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Si le nom d'un politique n'apparait pas en entier il n'est pas relevé par le Matcher. (résolu)\n",
    "- En ajoutant les noms seuls, à la liste des noms prénoms, on a un problème pour les entités qui se chevauchent (Hollande dans François Hollande) (résolu)\n",
    "- Le matcher relève le nom d'une personnalité politique autant de fois qu'elle est citée, si on s'intéresse aux nombres de citations\n",
    "différentes on mettra un *set()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expressions_extraction(texte,matcher):\n",
    "    doc = nlp(texte)\n",
    "    matches = matcher(doc)\n",
    "    return([doc[start:end] for match_id, start, end in matches])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#expressions_extraction(essai,matcher_politician)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['matcher'] = df['texte'].apply(lambda x : expressions_extraction(x, matcher))\n",
    "#df['taille matcher'] = df['matcher'].apply(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Création d'une nouvelle entité nommée : Politicien (POL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Span\n",
    "\n",
    "def politician_component(doc):\n",
    "    # Crée une entité Span avec le label \"POL\" pour toutes les correspondances\n",
    "    matches = matcher_politician(doc)\n",
    "    doc.ents = [Span(doc, start, end, label='POL') for match_id, start, end in matches]\n",
    "    return doc\n",
    "\n",
    "\n",
    "# Ajoute le composant au pipeline\n",
    "nlp.add_pipe(politician_component, before='ner')\n",
    "#print(nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On ajoute le composant à la recherche des noms de familles de politiciens, ceci règle le problème de non-repérage lorsqu'une personnalité politique est désignée par son nom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "POLITICIANS_surname = [politicien.split()[-1] for politicien in POLITICIANS]\n",
    "\n",
    "def politicians_surnames(doc):\n",
    "    new_ents = []\n",
    "    for ent in doc.ents:\n",
    "            if ent.text in POLITICIANS_surname:\n",
    "                new_ent = Span(doc, ent.start, ent.end, label='POL')\n",
    "                new_ents.append(new_ent)\n",
    "            else:\n",
    "                new_ents.append(ent)\n",
    "    doc.ents = new_ents\n",
    "    return doc\n",
    "\n",
    "nlp.add_pipe(politicians_surnames, after='ner')\n",
    "#print(nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Politiques'] = df['texte'].apply(lambda x: counter_label(x,'POL'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rappeler ```df```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"2019-01-08-editos-radio.csv\")\n",
    "df['auteur'] = df['auteur'].apply(lambda x: \" \".join(str(x).split()))\n",
    "df['texte']= df['texte'].apply(lambda x: \" \".join((str(x).split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = nlp(df.loc[10]['texte'])\n",
    "#displacy.render(text, style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(df.groupby('auteur').mean().reset_index()).plot.bar(x='auteur', y='Politiques', figsize=(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On note d'importante disparités, d'un editorialiste à un autre,dans l'évocation de figures politiques (Présidents, ministres (actuels et anciens), députés, eurodéputés, sénateurs, candidats à la présidentielle 2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin de pouvoir relever correctements les personalités politiques cités, on a besoin de \"fusionner\" certains résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "texte = nlp(df['texte'][7])\n",
    "liste=[ent.text for ent in texte.ents if ent.label_ =='POL']\n",
    "compteur=[(element,liste.count(element)) for element in set(liste)]\n",
    "#compteur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fusion(l1,l2):\n",
    "    liste_fusion=[]\n",
    "    liste_somme=l1+l2\n",
    "    for nom, comptage in liste_somme:\n",
    "        for name, count in liste_somme:\n",
    "            if nom.split()[-1] == name.split()[-1] and nom != name: #la fin du nom apparaît dans la liste\n",
    "                liste_somme.remove((nom, comptage))\n",
    "                liste_somme.remove((name, count))\n",
    "                if len(nom)>len(name):\n",
    "                    liste_fusion += [(nom, comptage + count)]\n",
    "                else:\n",
    "                    liste_fusion += [(name, comptage + count)]\n",
    "            elif nom == name and comptage != count:\n",
    "                liste_somme.remove((nom, comptage))\n",
    "                liste_somme.remove((name, count))\n",
    "                liste_fusion += [(nom, comptage + count)]\n",
    "                \n",
    "    return(liste_fusion + liste_somme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tri_fusion(liste):\n",
    "    if  len(liste) <= 1: \n",
    "        return liste\n",
    "    else:\n",
    "        pivot = len(liste)//2\n",
    "        liste1 = liste[:pivot]\n",
    "        liste2 = liste[pivot:]\n",
    "        gauche = tri_fusion(liste1)\n",
    "        droite = tri_fusion(liste2)\n",
    "        fusionne = fusion(gauche,droite)\n",
    "        return fusionne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On crée une nouvelle DataFrame qui relève toutes les citations de personnalités politique, par éditorialiste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Editorialistes = [auteur for auteur in set(df.auteur)]\n",
    "df_citations = pd.DataFrame(columns=['Auteur', 'Personnalité', 'Nb Citations'])\n",
    "\n",
    "for editorialiste in Editorialistes:\n",
    "    base = df[df['auteur']==editorialiste]\n",
    "    editos = base.texte\n",
    "    docs = list(nlp.pipe(editos)) #on traite directement tous les textes en même temps, c'est bcp plus rapide\n",
    "    ents = [doc.ents for doc in docs]\n",
    "\n",
    "    liste=[]\n",
    "    for i in range(len(ents)):\n",
    "        liste += [ent.text for ent in ents[i] if ent.label_ == 'POL']\n",
    "    \n",
    "    compteur=[(element,liste.count(element)) for element in set(liste)]\n",
    "    compteur_fusion = tri_fusion(compteur) \n",
    "    \n",
    "    for personnalite, nombre in compteur_fusion:\n",
    "        df_citations=df_citations.append({'Auteur': editorialiste ,'Personnalité': personnalite ,'Nb Citations': nombre}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Legrand_citations = df_citations[df_citations['Auteur']== 'Thomas Legrand']\n",
    "Top_20 = Legrand_citations[['Personnalité','Nb Citations']].sort_values(by='Nb Citations',ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top_20.plot(x='Personnalité', kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Duhamel_citations = df_citations[df_citations['Auteur']== 'Alain Duhamel']\n",
    "Top_20 = Duhamel_citations[['Personnalité','Nb Citations']].sort_values(by='Nb Citations',ascending=False).head(20)\n",
    "#Top_20.plot(x='Personnalité', kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_citations.groupby('Personnalité')['Nb Citations'].sum().sort_values(ascending=False).head(25).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Emmanuel Macron, ministre, candidat à la présidentielle puis président de la République est la personnalité politique la plus citée. Vient ensuite Francçois Hollande, président pendant toute la période pré-campagne et campagne. Les (gros) candidats à la présidentielle 2017 sont également beacoup cités, du fait de l'année d'élection présidentielle 2017. D'anciens présidents comme Jacques Chirac ou François Mitterand sont fréquement cités.\n",
    "\n",
    "Il est important de garder en tête que l'algorithme de trouve que ce qu l'on lui fait chercher, à savoir des noms issus d'une liste de ministres et présidents (passés et actuels), députés, sénateurs , eurodéputés et candidats en 2017. Et les noms à orthographes multiples peuvent se retrouver sous plusieurs formes. \n",
    "L'exemple qui suit le montre bien :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_citations[df_citations['Personnalité']=='Marine le Pen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_citations[df_citations['Personnalité']=='Marine Le Pen']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les personnalités (politiques ou non) citées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_personne = pd.DataFrame(columns=['Auteur', 'Personne', 'Nb Citations'])\n",
    "\n",
    "for editorialiste in Editorialistes:\n",
    "    base = df[df['auteur']==editorialiste]\n",
    "    editos = base.texte\n",
    "    docs = list(nlp.pipe(editos)) #on traite directement tous les textes en même temps, c'est bcp plus rapide\n",
    "    ents = [doc.ents for doc in docs]\n",
    "\n",
    "    liste=[]\n",
    "    for i in range(len(ents)):\n",
    "        liste += [ent.text for ent in ents[i] if ent.label_ == 'PER']\n",
    "    \n",
    "    compteur=[(element,liste.count(element)) for element in set(liste)]\n",
    "    compteur_fusion = tri_fusion(compteur) \n",
    "    \n",
    "    for personnalite, nombre in compteur_fusion:\n",
    "        df_personne=df_personne.append({'Auteur': editorialiste ,'Personne': personnalite ,'Nb Citations': nombre}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_personne.groupby('Personne')['Nb Citations'].sum().sort_values(ascending=False).head(25).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certaines fois, un mot ou deux précédants un nom sont relevés dans l'expression par le **Named Entity Recognizer**, la fonction ``` tri_fusion ``` ayant été codée pour fusionner *'Nom'* et *'Prénom Nom'* ou bien plusieurs orthographes de *'Prénom Nom'*. \n",
    "Il ya également des grandes chances que Marion Marechal Le Pen compte ici également pour Marine Le Pen... Ces résultats sont moins exploitables que les précédants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Expertise canonisée\" : rapports, études, chiffres\n",
    "\n",
    "#### Utilisation d'un matcher, pour trouver des expressions.\n",
    "- Ici on veut repérer la citation d'un rapport ou d'une étude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher\n",
    "matcher_rapport = Matcher(nlp.vocab)\n",
    "\n",
    "# On écrit un motif pour le mot rapport et les mots qui le suivent habituellement\n",
    "pattern = [{\"lower\": \"rapport\"},{\"POS\": \"ADP\", \"OP\":\"?\"},{\"POS\": \"DET\", \"OP\":\"?\"}, {\"POS\": \"PROPN\", \"OP\":\"+\"}]\n",
    "pattern_date=[{\"lower\": \"rapport\"},{\"POS\": \"ADP\", \"OP\":\"?\"},{\"POS\": \"DET\", \"OP\":\"?\"}, {\"POS\": \"PROPN\", \"OP\":\"?\"},\n",
    "           {\"POS\": \"ADP\", \"OP\":\"?\"},{\"POS\": \"NUM\",\"OP\":\"+\"}]\n",
    "pattern_theme = [{\"lower\": \"rapport\"},{\"POS\": \"ADP\", \"OP\":\"?\"},{\"POS\": \"DET\", \"OP\":\"?\"}, {\"POS\": \"NOUN\", \"OP\":\"+\"}]\n",
    "\n",
    "# On reprend les mêmes motifs pour une étude\n",
    "pattern_etude = [{\"lower\": \"étude\"},{\"POS\": \"ADP\", \"OP\":\"?\"},{\"POS\": \"DET\", \"OP\":\"?\"}, {\"POS\": \"PROPN\", \"OP\":\"+\"}]\n",
    "pattern_etude_date=[{\"lower\": \"étude\"},{\"POS\": \"ADP\", \"OP\":\"?\"},{\"POS\": \"DET\", \"OP\":\"?\"}, {\"POS\": \"PROPN\", \"OP\":\"?\"},\n",
    "           {\"POS\": \"ADP\", \"OP\":\"?\"},{\"POS\": \"NUM\",\"OP\":\"+\"}]\n",
    "pattern_etude_theme = [{\"lower\": \"étude\"},{\"POS\": \"ADP\", \"OP\":\"?\"},{\"POS\": \"DET\", \"OP\":\"?\"}, {\"POS\": \"NOUN\", \"OP\":\"+\"}]\n",
    "\n",
    "# Ajoute les motifs au matcher et applique le matcher au doc\n",
    "matcher_rapport.add(\"Rapport_PATTERN\", None, pattern)\n",
    "matcher_rapport.add(\"Rapport_PATTERN_date\",None,pattern_date)\n",
    "matcher_rapport.add(\"Rapport_PATTERN_date\",None,pattern_theme)\n",
    "matcher_rapport.add(\"Etude_PATTERN\", None, pattern_etude)\n",
    "matcher_rapport.add(\"Etude_PATTERN_date\",None,pattern_etude_date)\n",
    "matcher_rapport.add(\"Etude_PATTERN_date\",None,pattern_etude_theme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Un essai\n",
    "doc=nlp('Le rapport sur le Climat, Un rapport de 2014, Une étude sur les Gilets Jaunes, Le rapport Borloo, Le rapport Borloo 2019, Le rapport du GIEC, Le rapport de Jean-Louis Borloo, Le rapport du FMI 2012, un rapport de 2012 climat')\n",
    "matches = matcher_rapport(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: On veut supprimer les expressions qui sont contenues dans d'autres expressions identifiées par le matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_matcher_rapport(doc):\n",
    "    matches = matcher_rapport(doc)\n",
    "    matches_clear=[]\n",
    "    for i in range(len(matches[:-1])):\n",
    "        match_id, start, end = matches[i]\n",
    "        machid, debut, fin = matches[i+1]\n",
    "        if not str(doc[debut:fin]).startswith(str(doc[start:end])):\n",
    "            matches_clear+=[(match_id, start, end)]\n",
    "    if matches_clear != []:\n",
    "        matches_clear += [matches[-1]]\n",
    "    return(matches_clear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['rapports_etudes'] = df['texte'].apply(lambda x : expressions_extraction(x, clear_matcher_rapport))\n",
    "#df['taille_rapports_etudes'] = df['rapports_etudes'].apply(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- On essaie désormais de repérer les occurrences de données chiffrées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "essai=nlp('2 millions de Français, un français sur 30 n\\'est pas  favorable, 60% du PIB, 2017 un million, deux millions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher\n",
    "\n",
    "# Crée les motifs de correspondance\n",
    "pattern1 = [{\"POS\" : \"NUM\"}, {\"POS\": \"DET\",\"OP\": \"?\"},{\"POS\": \"NOUN\",\"OP\": \"?\"}]\n",
    "pattern2 = [{\"LIKE_NUM\" : True}, {\"Lower\" : \"million\"}]\n",
    "pattern3 = [{\"LIKE_NUM\" : True}, {\"Lower\" : \"milliard\"}]\n",
    "\n",
    "# Initialise le Matcher et ajoute les motifs\n",
    "matcher_chiffres = Matcher(nlp.vocab)\n",
    "matcher_chiffres.add(\"PATTERN1\", None, pattern1)\n",
    "matcher_chiffres.add(\"PATTERN1\", None, pattern2)\n",
    "matcher_chiffres.add(\"PATTERN1\", None, pattern3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_matcher_chiffres(doc):\n",
    "    matches = matcher_chiffres(doc)\n",
    "    matches_clear=[]\n",
    "    for i in range(len(matches[:-1])):\n",
    "        match_id, start, end = matches[i]\n",
    "        machid, debut, fin = matches[i+1]\n",
    "        if not str(doc[debut:fin]).startswith(str(doc[start:end])):\n",
    "            matches_clear+=[(match_id, start, end)]\n",
    "    if matches_clear != []:\n",
    "        matches_clear += [matches[-1]]\n",
    "    return(matches_clear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = nlp('Ya pas de chiffres dans ce test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Combinaison des 2 dans une entité nommé 'EXP' pour \"Expertise\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rapport_component(doc):\n",
    "    # Crée une entité Span avec le label \"EXP\" pour toutes les correspondances\n",
    "    matches = clear_matcher_rapport(doc) \n",
    "    doc.ents = [Span(doc, start, end, label='EXP') for match_id, start, end in matches]\n",
    "    return doc\n",
    "\n",
    "\n",
    "# Ajoute le composant au pipeline\n",
    "nlp.add_pipe(rapport_component, before ='ner')\n",
    "#print(nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chiffres_component(doc):\n",
    "    # Crée une entité Span avec le label \"EXP\" pour toutes les correspondances\n",
    "    matches = clear_matcher_chiffres(doc)\n",
    "    doc.ents = [Span(doc, start, end, label='EXP') for match_id, start, end in matches]\n",
    "    return doc\n",
    "\n",
    "\n",
    "# Ajoute le composant au pipeline\n",
    "nlp.add_pipe(chiffres_component, before ='ner')\n",
    "#print(nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Editorialistes = [auteur for auteur in set(df.auteur)]\n",
    "df_expertise = pd.DataFrame(columns=['Auteur', 'Citations', 'Nbre'])\n",
    "\n",
    "with nlp.disable_pipes(\"politician_component\", \"politicians_surnames\"): #pour éviter que certains composents n'en fassent oublier d'autres\n",
    "\n",
    "    for editorialiste in tqdm(Editorialistes):\n",
    "        base = df[df['auteur']==editorialiste]\n",
    "        editos = base.texte\n",
    "        docs = list(nlp.pipe(editos)) #on traite directement tous les textes en même temps, c'est bcp plus rapide\n",
    "        ents = [doc.ents for doc in docs]\n",
    "\n",
    "        liste=[]\n",
    "        for i in range(len(ents)):\n",
    "            liste += [ent.text for ent in ents[i] if ent.label_ == 'EXP']\n",
    "\n",
    "        compteur=[(element,liste.count(element)) for element in set(liste)]\n",
    "\n",
    "        for citation, nombre in compteur:\n",
    "            df_expertise = df_expertise.append({'Auteur': editorialiste , 'Citations': citation, 'Nbre': nombre}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_expertise.sample(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On se rend compte que dans les évocations de ce qu'on attend comme étant des 'Données chiffrées', un bon nombre de dates et des nombres qui n'ont pas grand choses à voir avec l'argumentation apparaissent. On peut au moins espérer que si notre 'filet' a des mailles trop fines, on ne rate pas grand chose..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_expertise.groupby('Auteur')['Nbre'].sum().sort_values(ascending=False).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dominique Seux est celui qui utilise le plus de données 'd'expertise', étant un analyste économique quand les autres sont des analystes politiques, on est presque rassuré de trouver ce résultat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mise en exergue des entités nommées dans un texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Legrand = df[df['auteur']=='Thomas Legrand']\n",
    "Legrand = Legrand.reset_index()\n",
    "\n",
    "Seux = df[df['auteur']=='Dominique Seux']\n",
    "Seux = Seux.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with nlp.disable_pipes(\"politician_component\", \"politicians_surnames\"):\n",
    "    texte=nlp(Seux['texte'][3])\n",
    "    #displacy.render(texte, style='ent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entraînement d'un nouveau modèle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jusque là, il était nécessaire de fournir dans notre code, soit une liste de noms à détecter, soit des règles très précises pour repérer certaines phrases. On se propose de dépasser ce stade de l'analyse en entrainant les modèles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le premier essai d'apprentissage concerne le repérage, dans un texte, d'une date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crée un modèle \"en\" vide\n",
    "nlp_date = spacy.blank(\"fr\")\n",
    "\n",
    "# Crée un nouvel entity recognizer et ajoute-le au pipeline\n",
    "ner = nlp_date.create_pipe(\"ner\")\n",
    "nlp_date.add_pipe(ner)\n",
    "\n",
    "# Ajoute le label \"DATE\" à l'entity recognizer\n",
    "ner.add_label(\"DAT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(\"phrase\", {\"entities\": [(15, 24, \"LABEL\")]},)\n",
    "\n",
    "TRAINING_DATA = [\n",
    "    (\"Nous sommes en 2021\", {'entities': [(15, 19, 'DAT')]},),\n",
    "    ('En sciences sociales comme en sciences la démarche se veut scientifique', {'entities': []},),\n",
    "    ('La dernière coupe du monde à eu lieu en 2018', {'entities': [(40, 44, \"DAT\")]},),\n",
    "    ('Il faut comprendre que 2014 est une date', {'entities': [(23, 27, \"DAT\")]},),\n",
    "    ('Le 19 octobre 2019, j\\'ai eu 20 ans', {'entities': [(3, 18, 'DAT' )]},),\n",
    "    ('La  culture de Soja détruit la forêt amazonienne', {'entities': []},),\n",
    "    ('Le Premier ministre adressera ses voeux aux français le 27 Janvier', {'entities': [(56,66, 'DAT')]},),\n",
    "    ('L\\'année 1933 Adol Hitler a été élu Chancelier d\\'Allemagne', {'entities': [(8, 12, 'DAT')]},),\n",
    "    ('Les éléctions européennes de 2019 ont confirmé la bonne dynamique des partis écolos', {'entities': [(29, 33, 'DAT')]},)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "# Commence l'apprentissage\n",
    "nlp_date.begin_training()\n",
    "\n",
    "# Boucle pour 20 itérations\n",
    "for itn in range(20):\n",
    "    # Mélange les données d'apprentissage\n",
    "    random.shuffle(TRAINING_DATA)\n",
    "    losses = {}\n",
    "\n",
    "    # Répartis les exemples en lots et itère dessus\n",
    "    for batch in spacy.util.minibatch(TRAINING_DATA):\n",
    "        texts = [text for text, entities in batch]\n",
    "        annotations = [entities for text, entities in batch]\n",
    "\n",
    "        # Actualise le modèle\n",
    "        nlp_date.update(texts, annotations, losses=losses)\n",
    "    #print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_date=nlp_date('En 2017 François Hollande ne s\\'est pas présenté en économie ? mais peut être va-t-il faire un retour en 2022. On le saura le 13 Février.')\n",
    "#nlp_date.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#doc_date.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texte=nlp(Seux['texte'][14])\n",
    "#displacy.render(texte, style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(token, token.pos_) for token in texte]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
