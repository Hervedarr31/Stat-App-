{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "from operator import add\n",
    "#import spacy\n",
    "#from spacy import displacy\n",
    "#from spacy.tokenizer import Tokenizer\n",
    "#from spacy.lang.fr import French\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/paolaricou/Documents/Stat-App-/2019-01-08-editos-radio.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emission</th>\n",
       "      <th>date</th>\n",
       "      <th>auteur</th>\n",
       "      <th>texte</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Europe1 Nay</td>\n",
       "      <td>2015-12-05</td>\n",
       "      <td>\\n                            Catherine Nay\\n ...</td>\n",
       "      <td>Avec un chômage au plus bas, la chancelière au...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Europe1 Nay</td>\n",
       "      <td>2015-12-12</td>\n",
       "      <td>\\n                            Catherine Nay\\n ...</td>\n",
       "      <td>Donald Trump, à 69 ans, pèse 4 milliards de do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Europe1 Nay</td>\n",
       "      <td>2015-12-19</td>\n",
       "      <td>\\n                            Catherine Nay\\n ...</td>\n",
       "      <td>\\nW.B. : François Hollande revient dans la co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Europe1 Nay</td>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>\\n                            Catherine Nay\\n ...</td>\n",
       "      <td>Que ce soit sur la déchéance de nationalité ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Europe1 Nay</td>\n",
       "      <td>2016-01-09</td>\n",
       "      <td>\\n                            Catherine Nay\\n ...</td>\n",
       "      <td>WB : Hier, cela faisait 20 ans que François Mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2251</th>\n",
       "      <td>FrCulture Says</td>\n",
       "      <td>2019-01-08</td>\n",
       "      <td>Frédéric Says</td>\n",
       "      <td>Posture ferme, et doigt tendu. Edouard Philipp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2252</th>\n",
       "      <td>FrInter Legrand</td>\n",
       "      <td>2019-01-08</td>\n",
       "      <td>Thomas Legrand</td>\n",
       "      <td>\\n            Le Rassemblement-National et LFI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2253</th>\n",
       "      <td>FrInter Seux</td>\n",
       "      <td>2019-01-08</td>\n",
       "      <td>Dominique Seux</td>\n",
       "      <td>\\n            Une question toute simple ce mat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2254</th>\n",
       "      <td>RTL Duhamel</td>\n",
       "      <td>2019-01-08</td>\n",
       "      <td>\\n                    Alain Duhamel\\n         ...</td>\n",
       "      <td>Édouard Philippe voulait afficher une grande f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2255</th>\n",
       "      <td>RTL Ventura</td>\n",
       "      <td>2019-01-08</td>\n",
       "      <td>\\n                    Alba Ventura\\n          ...</td>\n",
       "      <td>Édouard Philippe a annoncé une série de mesure...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2256 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             emission        date  \\\n",
       "0         Europe1 Nay  2015-12-05   \n",
       "1         Europe1 Nay  2015-12-12   \n",
       "2         Europe1 Nay  2015-12-19   \n",
       "3         Europe1 Nay  2016-01-02   \n",
       "4         Europe1 Nay  2016-01-09   \n",
       "...               ...         ...   \n",
       "2251   FrCulture Says  2019-01-08   \n",
       "2252  FrInter Legrand  2019-01-08   \n",
       "2253     FrInter Seux  2019-01-08   \n",
       "2254      RTL Duhamel  2019-01-08   \n",
       "2255      RTL Ventura  2019-01-08   \n",
       "\n",
       "                                                 auteur  \\\n",
       "0     \\n                            Catherine Nay\\n ...   \n",
       "1     \\n                            Catherine Nay\\n ...   \n",
       "2     \\n                            Catherine Nay\\n ...   \n",
       "3     \\n                            Catherine Nay\\n ...   \n",
       "4     \\n                            Catherine Nay\\n ...   \n",
       "...                                                 ...   \n",
       "2251                                      Frédéric Says   \n",
       "2252                                     Thomas Legrand   \n",
       "2253                                     Dominique Seux   \n",
       "2254  \\n                    Alain Duhamel\\n         ...   \n",
       "2255  \\n                    Alba Ventura\\n          ...   \n",
       "\n",
       "                                                  texte  \n",
       "0     Avec un chômage au plus bas, la chancelière au...  \n",
       "1     Donald Trump, à 69 ans, pèse 4 milliards de do...  \n",
       "2      \\nW.B. : François Hollande revient dans la co...  \n",
       "3       Que ce soit sur la déchéance de nationalité ...  \n",
       "4     WB : Hier, cela faisait 20 ans que François Mi...  \n",
       "...                                                 ...  \n",
       "2251  Posture ferme, et doigt tendu. Edouard Philipp...  \n",
       "2252  \\n            Le Rassemblement-National et LFI...  \n",
       "2253  \\n            Une question toute simple ce mat...  \n",
       "2254  Édouard Philippe voulait afficher une grande f...  \n",
       "2255  Édouard Philippe a annoncé une série de mesure...  \n",
       "\n",
       "[2256 rows x 4 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "L=df['emission'].unique()\n",
    "\n",
    "#Liste par éditorialistes\n",
    "Nay=df[df['emission'] == L[0]]\n",
    "Duhamel=df[df['emission'] == L[1]]\n",
    "Ventura=df[df['emission'] == L[2]]\n",
    "Says=df[df['emission'] == L[3]]\n",
    "Legrand=df[df['emission'] == L[4]]\n",
    "Seux=df[df['emission'] == L[5]]\n",
    "Darmon=df[df['emission'] == L[6]]\n",
    "\n",
    "#Listes par radio\n",
    "FrInter=Legrand+Seux\n",
    "FrCulture=Says\n",
    "Europe1=Nay+Darmon\n",
    "RTL=Duhamel+Ventura\n",
    "\n",
    "Radio=[FrInter, FrCulture, Europe1, RTL]\n",
    "Editorialistes=[Nay, Duhamel, Ventura, Says, Legrand, Seux, Darmon]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E1153 : RTL Ventura : Égalité Homme/Femme, qu\\'en est-il en france? Des inégalités persistente, \\ndevrons nous durcir les lois\\nE1154: FrCulture Says : Les prisons et leur prise en main, comment entretenir une \"paix\" carcérale, \\nen particulier pb des radicalisé. Politique, Justice, Prison. \\nE1155: Frinter Legrand: NDDL une cause populaire qui a gagné, les autorités publics et jusqu\\'où aller pour maintenir\\nl\\'ordre (qu\\'est-il d\\'ailleurs?). Politique, Autorité publique, Écologie\\nE1156 : FrInter Seux: L\\'anglais la langue de l\\'économie, LREM un parti qui innove en parlant bien anglais, \\nrencontre économique à Versailles instauré par Macron\\n\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Bref résumé d'éditos lu au hasard\n",
    "\n",
    "\"\"\"E0 (Europe 1 Nay): sur la politique allemande : l'accueil des migrants, l'europe et la réélection de Merkel \n",
    "Sujet : Immigration, Europe, Politique, Allemagne(Merkel)\n",
    "E1000 (FRInter Legrand) 2017_12_01: Politique française : Macron une voie politique en bonne position \n",
    "entre deux bords qui se déchirent. Politique\n",
    "E1151 (Frinter Dominique Seux): Les tentatives de Macron pour attirer les investisseurs étrangers sur \n",
    "L'économie française et pourquoi les français ont ils\n",
    "une si mauvaise opinion sur leur propre économie. Sujet: économie, economie industrielle, politique\n",
    "E1152: RTL Duhamel\t2018-01-22: L'avenir de le l'alliance franco- allemande à la veille des élections allemande. \n",
    "Politique Franco-Allemande\"\"\"\n",
    "#Tips : Réélection de Merkel le 14 Mars 2018 \n",
    "\"\"\"E1153 : RTL Ventura : Égalité Homme/Femme, qu'en est-il en france? Des inégalités persistente, \n",
    "devrons nous durcir les lois\n",
    "E1154: FrCulture Says : Les prisons et leur prise en main, comment entretenir une \"paix\" carcérale, \n",
    "en particulier pb des radicalisé. Politique, Justice, Prison. \n",
    "E1155: Frinter Legrand: NDDL une cause populaire qui a gagné, les autorités publics et jusqu'où aller pour maintenir\n",
    "l'ordre (qu'est-il d'ailleurs?). Politique, Autorité publique, Écologie\n",
    "E1156 : FrInter Seux: L'anglais la langue de l'économie, LREM un parti qui innove en parlant bien anglais, \n",
    "rencontre économique à Versailles instauré par Macron\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n            Le paysage politique de l’ère Macron devient lisible…  \\n        \\nOui, nous sommes dans un moment de cristallisation politique. Chacun a maintenant les éléments pour commencer à se situer sur le nouvel échiquier après les bouleversements provoqués par l’élection d’Emmanuel Macron. Nous avons un large bloc central qui occupe un espace institutionnel surdimensionné. Espace qui vient encore de s’élargir de quelques pouces par les 2 bouts. Par la gauche d’abord, \\xa0\\xa0avec l’entrée au gouvernement d’un député PS, certes peu connu, sans scrupule ni colonne vertébrale, mais socialiste quand même\\xa0: Oliviers Dussopt nommé secrétaire d’Etat alors qu’il était contre la loi de finance et qu’il avait aussi voté contre les ordonnances, lois signatures du macronisme s’il en est ! Et par la droite avec l’adhésion formelle et logique à LREM de 2 ministres et d’un député ex-LR. Cet empire du milieu gonflé à l’hélium du fait-majoritaire repousse les oppositions sur les extrêmes. Le PS, LR et le FN, sont, en ce moment, un peu absents pour travaux. Seul LFI est en ordre de marche (à un débat interne sur la laïcité près). La majorité \\xa0a sur ses flans 2 oppositions dont les discours s’annihilent et donnent à celui du gouvernement l’éclat valorisant et trop aisé de l’équilibre et de la raison. Ainsi avec la loi de sécurité intérieure, taxée de laxiste par la droite et de liberticide par la gauche, la majorité n’avait plus qu’à laisser dire !\\nEmmanuel Macron, dont la politique semblait pencher à droite, tente, un rééquilibrage...\\xa0\\nOui, ses discours (en attendant les actes !) sur les banlieues, sur les violences sexistes, reprenaient mot pour mot les arguments de la gauche. Il y a une cohérence libérale, économique et sociétale inédite en France et qui constitue un élément déstabilisateur pour les partis classiques. LREM semble avoir retrouvé ses 2 jambes et placé les oppositions dans une centrifugeuse. Oppositions qui ne peuvent pas –pour l’instant du moins- apparaître comme des alternatives crédibles, du fait de leurs inévitables divisions et de leurs radicalités forcées. Ce qui affaiblit considérablement leur parole parce que si on entend un opposant protestataire, on écoute et on tient compte d’un opposant qui a la surface pour être une alternative. Emmanuel Macron dispose donc d’une latitude inédite. Imaginez, si son opposition est représentée par Jean-Luc Mélenchon d’un côté et Laurent Wauquiez de l’autre, il est alors dans une configuration idéale pour appliquer son programme. Si vous ajoutez la possibilité de voir en Allemagne une majorité amie composée du SPD, de la CDU et des Verts, Emmanuel Macron aura vraiment toutes les manettes en main. Mais le charme de la nouveauté ne durera pas et certaines manettes pourraient se gripper, d’autant que les solutions proposées par le président ne sont que relativement majoritaires dans l’opinion. Elles sont majoritaires, \\xa0absolues simplement du fait de la mécanique de nos institutions. Elles doivent donc vite produire leurs effets et dessiner beaucoup plus clairement le but, l’horizon vers lequel la majorité est En Marche. Parce qu’attention\\xa0: comme disait le grand père de Spiderman quand celui-ci lui avouait l’immensité de ses pouvoirs « avec de grands pouvoirs viennent les grandes responsabilités ».\\xa0'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ 7, 15, 25, 54, 89, 134, 150, 167, 245, 278, 290, 309, 356, 398, 408, 412, 476, 510, 550, 572, 632, 683, 684, 732, 745, 763, 826, 854, 888, 921, 973, 1000]\n",
    "\n",
    "df['texte'].iloc[1000]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import bs4\n",
    "import pandas\n",
    "from urllib import request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lexique diplomatie \n",
    "url_mots='https://fr.wiktionary.org/wiki/Cat%C3%A9gorie:Lexique_en_fran%C3%A7ais_de_la_diplomatie'\n",
    "\n",
    "request_text = request.urlopen(url_mots).read()\n",
    "\n",
    "page = bs4.BeautifulSoup(request_text, \"lxml\")\n",
    "\n",
    "main=page.find('main')\n",
    "tab=main.findAll('li')\n",
    "\n",
    "diplomatie=[]\n",
    "for x in tab:\n",
    "    table_body = x.find('a')\n",
    "    for x in table_body: \n",
    "        diplomatie.append(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lexique idéologies politiques \n",
    "url_mots='https://fr.wiktionary.org/wiki/Cat%C3%A9gorie:Id%C3%A9ologies_politiques_en_fran%C3%A7ais'\n",
    "\n",
    "request_text = request.urlopen(url_mots).read()\n",
    "\n",
    "page = bs4.BeautifulSoup(request_text, \"lxml\")\n",
    "\n",
    "main=page.find('main')\n",
    "tab=main.findAll('li')\n",
    "\n",
    "ideologies=[]\n",
    "for x in tab:\n",
    "    table_body = x.find('a')\n",
    "    for x in table_body: \n",
    "        ideologies.append(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lexique Franc-maçon\n",
    "url_mots='https://fr.wiktionary.org/wiki/Cat%C3%A9gorie:Lexique_en_fran%C3%A7ais_de_la_franc-ma%C3%A7onnerie'\n",
    "\n",
    "request_text = request.urlopen(url_mots).read()\n",
    "\n",
    "page = bs4.BeautifulSoup(request_text, \"lxml\")\n",
    "\n",
    "main=page.find('main')\n",
    "tab=main.findAll('li')\n",
    "\n",
    "franc_macon=[]\n",
    "for x in tab:\n",
    "    table_body = x.find('a')\n",
    "    for x in table_body: \n",
    "        franc_macon.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lexique Monarchie \n",
    "url_mots='https://fr.wiktionary.org/wiki/Cat%C3%A9gorie:Lexique_en_fran%C3%A7ais_de_la_monarchie'\n",
    "\n",
    "request_text = request.urlopen(url_mots).read()\n",
    "\n",
    "page = bs4.BeautifulSoup(request_text, \"lxml\")\n",
    "\n",
    "main=page.find('main')\n",
    "tab=main.findAll('li')\n",
    "\n",
    "monarchie=[]\n",
    "for x in tab:\n",
    "    table_body = x.find('a')\n",
    "    for x in table_body: \n",
    "        monarchie.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lexique Relations internationales  \n",
    "url_mots='https://fr.wiktionary.org/wiki/Cat%C3%A9gorie:Lexique_en_fran%C3%A7ais_des_relations_internationales'\n",
    "\n",
    "request_text = request.urlopen(url_mots).read()\n",
    "\n",
    "page = bs4.BeautifulSoup(request_text, \"lxml\")\n",
    "\n",
    "main=page.find('main')\n",
    "tab=main.findAll('li')\n",
    "\n",
    "ri=[]\n",
    "for x in tab:\n",
    "    table_body = x.find('a')\n",
    "    for x in table_body: \n",
    "        ri.append(x)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lexique du socialisme \n",
    "url_mots='https://fr.wiktionary.org/wiki/Cat%C3%A9gorie:Lexique_en_fran%C3%A7ais_du_socialisme'\n",
    "\n",
    "request_text = request.urlopen(url_mots).read()\n",
    "\n",
    "page = bs4.BeautifulSoup(request_text, \"lxml\")\n",
    "\n",
    "main=page.find('main')\n",
    "tab=main.findAll('li')\n",
    "\n",
    "socialisme=[]\n",
    "for x in tab:\n",
    "    table_body = x.find('a')\n",
    "    for x in table_body: \n",
    "        socialisme.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lexique systèmes électoraux\n",
    "\n",
    "url_mots='https://fr.wiktionary.org/wiki/Cat%C3%A9gorie:Lexique_en_fran%C3%A7ais_des_syst%C3%A8mes_%C3%A9lectoraux'\n",
    "\n",
    "request_text = request.urlopen(url_mots).read()\n",
    "\n",
    "page = bs4.BeautifulSoup(request_text, \"lxml\")\n",
    "\n",
    "main=page.find('main')\n",
    "tab=main.findAll('li')\n",
    "\n",
    "sys_electoral=[]\n",
    "for x in tab:\n",
    "    table_body = x.find('a')\n",
    "    for x in table_body: \n",
    "        sys_electoral.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lexique UE\n",
    "\n",
    "url_mots='https://fr.wiktionary.org/wiki/Cat%C3%A9gorie:Lexique_en_fran%C3%A7ais_de_l%E2%80%99Union_europ%C3%A9enne'\n",
    "\n",
    "request_text = request.urlopen(url_mots).read()\n",
    "\n",
    "page = bs4.BeautifulSoup(request_text, \"lxml\")\n",
    "\n",
    "main=page.find('main')\n",
    "tab=main.findAll('li')\n",
    "\n",
    "UE=[]\n",
    "for x in tab:\n",
    "    table_body = x.find('a')\n",
    "    for x in table_body: \n",
    "        UE.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lexique Vexillologie\n",
    "\n",
    "url_mots='https://fr.wiktionary.org/wiki/Cat%C3%A9gorie:Lexique_en_fran%C3%A7ais_de_la_vexillologie'\n",
    "\n",
    "request_text = request.urlopen(url_mots).read()\n",
    "\n",
    "page = bs4.BeautifulSoup(request_text, \"lxml\")\n",
    "\n",
    "main=page.find('main')\n",
    "tab=main.findAll('li')\n",
    "\n",
    "Vex=[]\n",
    "for x in tab:\n",
    "    table_body = x.find('a')\n",
    "    for x in table_body: \n",
    "        Vex.append(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Importe le Matcher\n",
    "from spacy.matcher import Matcher\n",
    "#Charge le modèle et crée l'objet nlp\n",
    "nlp = spacy.load(\"fr_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_matchers(l, matcher):\n",
    "    for i in range(len(l)):\n",
    "        doc = nlp(str(l[i]))\n",
    "        pattern = []\n",
    "        for token in doc:\n",
    "                if (token.pos_ == 'VERB' or token.pos_ == 'AUX'):\n",
    "                    pattern.append({\"LEMMA\" : str(token), 'POS' : token.pos_})\n",
    "                elif token.pos_== 'NOUN':\n",
    "                    pattern.append({\"LEMMA\" : str(token), 'POS' : 'NOUN'})\n",
    "                elif token.pos_== 'DET':\n",
    "                    pattern.append({'POS' : 'DET'})   \n",
    "                else:\n",
    "                    pattern.append({'LOWER' : str(token)})\n",
    "        matcher.add(str(i), None, pattern)\n",
    "\n",
    "\n",
    "def expressions_extraction(texte,matcher):\n",
    "    doc = nlp(texte)\n",
    "    matches = matcher(doc)\n",
    "    return([doc[start:end] for match_id, start, end in matches])\n",
    "\n",
    "def add_feature_matcher(df, expressions):\n",
    "    matcher = Matcher(nlp.vocab)\n",
    "    add_matchers(expressions,matcher)\n",
    "    df['matcher'] = df['texte'].apply(lambda x : expressions_extraction(x, matcher))\n",
    "    df['taille matcher'] = df['matcher'].apply(len)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-014dcf04d269>:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['matcher'] = df['texte'].apply(lambda x : expressions_extraction(x, matcher))\n",
      "<ipython-input-25-014dcf04d269>:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['taille matcher'] = df['matcher'].apply(len)\n"
     ]
    }
   ],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "L=[]\n",
    "\n",
    "for x in Editorialistes:\n",
    "    M1=add_feature_matcher(x, UE)\n",
    "    k=0\n",
    "    for i in range (len(M1)):\n",
    "        if M1['taille matcher'].iloc[i]!=0:\n",
    "            k+=M1['taille matcher'].iloc[i]\n",
    "    L.append(k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(['Nay', 'Duhamel', 'Ventura', 'Says', 'Legrand', 'Seux', 'Darmon'], L)\n",
    "plt.title('Fréquence du lexique UE par éditorialiste')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iPhone 12\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for match_id, start, end in matches:\n",
    "    #print(\"Correspondance trouvée :\", doc[start:end].text)\n",
    "    print(str(doc[start:end]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nuages de mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nuage de mots sur un seul texte \n",
    "\n",
    "def generate_wordcloud(text): # optionally add: stopwords=STOPWORDS and change the arg below\n",
    "    wordcloud = WordCloud(font_path='/Library/Fonts/Verdana.ttf',\n",
    "                          relative_scaling = 1.0,\n",
    "                          stopwords = {'to', 'of'} # set or space-separated string\n",
    "                          ).generate(text)\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_sentence =[] \n",
    "for x in Nay['texte']:\n",
    "    #  \"nlp\" Object is used to create documents with linguistic annotations.\n",
    "    my_doc = nlp(x)\n",
    "    # Create list of word tokens\n",
    "    token_list = []\n",
    "    for token in my_doc:\n",
    "        token_list.append(token.text)\n",
    "\n",
    "    # Create list of word tokens after removing stopwords\n",
    "    for word in token_list:\n",
    "        lexeme = nlp.vocab[word]\n",
    "        if lexeme.is_stop == False and lexeme!= 'y':\n",
    "            filtered_sentence.append(word) \n",
    "filtered_Nay=' '.join(filtered_sentence)\n",
    "\n",
    "filtered_sentence =[] \n",
    "for x in Legrand['texte']:\n",
    "    #  \"nlp\" Object is used to create documents with linguistic annotations.\n",
    "    my_doc = nlp(x)\n",
    "    # Create list of word tokens\n",
    "    token_list = []\n",
    "    for token in my_doc:\n",
    "        token_list.append(token.text)\n",
    "\n",
    "    # Create list of word tokens after removing stopwords\n",
    "    for word in token_list:\n",
    "        lexeme = nlp.vocab[word]\n",
    "        if lexeme.is_stop == False and lexeme!= 'y':\n",
    "            filtered_sentence.append(word) \n",
    "filtered_Legrand=' '.join(filtered_sentence)\n",
    "\n",
    "filtered_sentence =[] \n",
    "for x in Duhamel['texte']:\n",
    "    #  \"nlp\" Object is used to create documents with linguistic annotations.\n",
    "    my_doc = nlp(x)\n",
    "    # Create list of word tokens\n",
    "    token_list = []\n",
    "    for token in my_doc:\n",
    "        token_list.append(token.text)\n",
    "\n",
    "    # Create list of word tokens after removing stopwords\n",
    "    for word in token_list:\n",
    "        lexeme = nlp.vocab[word]\n",
    "        if lexeme.is_stop == False and lexeme!= 'y':\n",
    "            filtered_sentence.append(word) \n",
    "filtered_Duhamel=' '.join(filtered_sentence)\n",
    "\n",
    "filtered_sentence =[] \n",
    "for x in Seux['texte']:\n",
    "    #  \"nlp\" Object is used to create documents with linguistic annotations.\n",
    "    my_doc = nlp(x)\n",
    "    # Create list of word tokens\n",
    "    token_list = []\n",
    "    for token in my_doc:\n",
    "        token_list.append(token.text)\n",
    "\n",
    "    # Create list of word tokens after removing stopwords\n",
    "    for word in token_list:\n",
    "        lexeme = nlp.vocab[word]\n",
    "        if lexeme.is_stop == False and lexeme!='y':\n",
    "            filtered_sentence.append(word) \n",
    "filtered_Seux=' '.join(filtered_sentence)\n",
    "\n",
    "filtered_sentence =[] \n",
    "for x in Ventura['texte']:\n",
    "    #  \"nlp\" Object is used to create documents with linguistic annotations.\n",
    "    my_doc = nlp(x)\n",
    "    # Create list of word tokens\n",
    "    token_list = []\n",
    "    for token in my_doc:\n",
    "        token_list.append(token.text)\n",
    "\n",
    "    # Create list of word tokens after removing stopwords\n",
    "    for word in token_list:\n",
    "        lexeme = nlp.vocab[word]\n",
    "        if lexeme.is_stop == False and lexeme!='y':\n",
    "            filtered_sentence.append(word) \n",
    "filtered_Ventura=' '.join(filtered_sentence)\n",
    "\n",
    "filtered_sentence =[] \n",
    "for x in Says['texte']:\n",
    "    #  \"nlp\" Object is used to create documents with linguistic annotations.\n",
    "    my_doc = nlp(x)\n",
    "    # Create list of word tokens\n",
    "    token_list = []\n",
    "    for token in my_doc:\n",
    "        token_list.append(token.text)\n",
    "\n",
    "    # Create list of word tokens after removing stopwords\n",
    "    for word in token_list:\n",
    "        lexeme = nlp.vocab[word]\n",
    "        if lexeme.is_stop == False and lexeme!='y':\n",
    "            filtered_sentence.append(word) \n",
    "filtered_Says=' '.join(filtered_sentence)\n",
    "\n",
    "filtered_sentence =[] \n",
    "for x in Darmon['texte']:\n",
    "    #  \"nlp\" Object is used to create documents with linguistic annotations.\n",
    "    my_doc = nlp(x)\n",
    "    # Create list of word tokens\n",
    "    token_list = []\n",
    "    for token in my_doc:\n",
    "        token_list.append(token.text)\n",
    "\n",
    "    # Create list of word tokens after removing stopwords\n",
    "    for word in token_list:\n",
    "        lexeme = nlp.vocab[word]\n",
    "        if lexeme.is_stop == False and lexeme!='y':\n",
    "            filtered_sentence.append(word) \n",
    "filtered_Darmon=' '.join(filtered_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_wordcloud(filtered_Legrand)\n",
    "generate_wordcloud(filtered_Seux)\n",
    "generate_wordcloud(filtered_Nay)\n",
    "generate_wordcloud(filtered_Duhamel)\n",
    "generate_wordcloud(filtered_Darmon)\n",
    "generate_wordcloud(filtered_Ventura)\n",
    "generate_wordcloud(filtered_Says)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
